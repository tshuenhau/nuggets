{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuotesByAuthor(author, page_num = None):\n",
    "    old_author = author\n",
    "    author = author.replace(\" \", \"+\")\n",
    "    all_quotes = []\n",
    "\n",
    "    # if page number not specified, get true page number\n",
    "    if page_num is None:\n",
    "        try:\n",
    "            page = requests.get(\"https://www.goodreads.com/quotes/search??utf8=%E2%9C%93&q=\" + author + \"&commit=Search\")\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "            pages = soup.find(class_=\"smallText\").text\n",
    "            of = pages.find(\"of \")\n",
    "            showing = pages.find(\"Showing \")\n",
    "\n",
    "            num_shown = pages[showing+10:of-1]\n",
    "            total_num = pages[of+3:]\n",
    "            total_num = total_num.replace(\",\", \"\").replace(\"\\n\", \"\")\n",
    "            num_shown = int(num_shown)\n",
    "            total_num = int(total_num)\n",
    "            page_num = math.ceil(total_num/num_shown)\n",
    "            print(\"looking through\", page_num, \"pages\")\n",
    "        except:\n",
    "            page_num = 1\n",
    "    \n",
    "    # for each page\n",
    "    for i in range(1, page_num+1, 1):\n",
    "\n",
    "        try:\n",
    "            page = requests.get(\"https://www.goodreads.com/quotes/search?commit=Search&page=\" + str(i) + \"&q=\" + author + \"&utf8=%E2%9C%93\")\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "            print(\"scraping page\", i)\n",
    "        except:\n",
    "            print(\"could not connect to goodreads\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            quote = soup.find(class_=\"leftContainer\")\n",
    "            quote_list = quote.find_all(class_=\"quoteDetails\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # get data for each quote\n",
    "        for quote in quote_list:\n",
    "\n",
    "            meta_data = []\n",
    "            # Get quote's author\n",
    "            try:\n",
    "                qAuthor = quote.find(class_=\"authorOrTitle\").text\n",
    "                qAuthor = qAuthor.replace(\",\", \"\")\n",
    "                qAuthor = qAuthor.replace(\"\\n\", \"\")\n",
    "                qAuthor = qAuthor.strip()\n",
    "                if(qAuthor != author):\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    meta_data.append(author.strip())\n",
    "                    print(author)\n",
    "            except:\n",
    "                meta_data.append(None)\n",
    "\n",
    "            # Get quote's text\n",
    "            try:\n",
    "                outer = quote.find(class_=\"quoteText\")\n",
    "                inner_text = [element for element in outer if isinstance(element, NavigableString)]\n",
    "                inner_text = [x.replace(\"\\n\", \"\") for x in inner_text]\n",
    "                final_quote = \"\\n\".join(inner_text[:-4])\n",
    "                meta_data.append(final_quote.strip())\n",
    "            except:\n",
    "                pass \n",
    "\n",
    "            \n",
    "            # Get quote's book title\n",
    "            try: \n",
    "                title = quote.find(class_=\"authorOrTitle\")\n",
    "                title = title.nextSibling.nextSibling.text\n",
    "                # title = title.replace(\"\\n\", \"\")\n",
    "                meta_data.append(title.strip())\n",
    "                # print(title)\n",
    "            except:\n",
    "                meta_data.append(None)\n",
    "\n",
    "            # Get quote's tags\n",
    "            try:\n",
    "                tags = quote.find(class_=\"greyText smallText left\").text\n",
    "                tags = [x.strip() for x in tags.split(',')]\n",
    "                tags = tags[1:]\n",
    "                meta_data.append(tags)\n",
    "                # print(tags)\n",
    "            except:\n",
    "                meta_data.append(None)\n",
    "\n",
    "            # Get number of likes\n",
    "            try:\n",
    "                likes = quote.find(class_=\"right\").text\n",
    "                likes = likes.replace(\"likes\", \"\")\n",
    "                likes = int(likes)\n",
    "                meta_data.append(likes)\n",
    "                # print(likes)\n",
    "            except:\n",
    "                meta_data.append(None)\n",
    "\n",
    "            all_quotes.append(meta_data)\n",
    "\n",
    "\n",
    "        for text, author, title, tags, likes in all_quotes:\n",
    "            print(text)\n",
    "            print(author)\n",
    "            print(title)\n",
    "            print(tags)\n",
    "            print(likes)\n",
    "            print()\n",
    "\n",
    "    return all_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking through 473 pages\n"
     ]
    }
   ],
   "source": [
    "all_quotes = []\n",
    "author = \"Shakespeare\"\n",
    "old_author = author\n",
    "page_num = 1;\n",
    "author = author.replace(\" \", \"+\")\n",
    "\n",
    "page = requests.get(\"https://www.goodreads.com/quotes/search??utf8=%E2%9C%93&q=\" + author + \"&commit=Search\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "pages = soup.find(class_=\"smallText\").text\n",
    "of = pages.find(\"of \")\n",
    "showing = pages.find(\"Showing \")\n",
    "\n",
    "num_shown = pages[showing+10:of-1]\n",
    "total_num = pages[of+3:]\n",
    "total_num = total_num.replace(\",\", \"\").replace(\"\\n\", \"\")\n",
    "num_shown = int(num_shown)\n",
    "total_num = int(total_num)\n",
    "page_num = math.ceil(total_num/num_shown)\n",
    "print(\"looking through\", page_num, \"pages\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    page = requests.get(\"https://www.goodreads.com/quotes/search?commit=Search&page=\" + str(1) + \"&q=\" + author + \"&utf8=%E2%9C%93\")\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    print(\"scraping page\", 1)\n",
    "except:\n",
    "    print(\"could not connect to goodreads\")\n",
    "\n",
    "try:\n",
    "    quote = soup.find(class_=\"leftContainer\")\n",
    "    quote_list = quote.find_all(class_=\"quoteDetails\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "     # get data for each quote\n",
    "for quote in quote_list:\n",
    "\n",
    "    meta_data = []\n",
    "            # Get quote's author\n",
    "    try:\n",
    "        qAuthor = quote.find(class_=\"authorOrTitle\").text\n",
    "        qAuthor = qAuthor.replace(\",\", \"\")\n",
    "        qAuthor = qAuthor.replace(\"\\n\", \"\")\n",
    "        qAuthor = qAuthor.strip()\n",
    "        if(qAuthor != author):\n",
    "            continue\n",
    "                \n",
    "        else:\n",
    "            meta_data.append(author.strip())\n",
    "                # print(author)\n",
    "    except:\n",
    "        meta_data.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William Shakespeare'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qAuthor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuotesByAuthor(\"William Shakespeare\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nuggets]",
   "language": "python",
   "name": "conda-env-nuggets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
